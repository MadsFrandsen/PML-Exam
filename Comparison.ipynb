{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "from models.models import DiffusionNet, LadderVAE\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from typing import Tuple\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if gpu else \"cpu\")\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model parameters:  1157560\n",
      "LadderVAE(\n",
      "  (encoder): ModuleList(\n",
      "    (0): LadderEncoder(\n",
      "      (linear): Linear(in_features=784, out_features=512, bias=True)\n",
      "      (batchnorm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (mu): Linear(in_features=512, out_features=64, bias=True)\n",
      "      (var): Linear(in_features=512, out_features=64, bias=True)\n",
      "    )\n",
      "    (1): LadderEncoder(\n",
      "      (linear): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (batchnorm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (mu): Linear(in_features=256, out_features=32, bias=True)\n",
      "      (var): Linear(in_features=256, out_features=32, bias=True)\n",
      "    )\n",
      "    (2): LadderEncoder(\n",
      "      (linear): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (mu): Linear(in_features=128, out_features=16, bias=True)\n",
      "      (var): Linear(in_features=128, out_features=16, bias=True)\n",
      "    )\n",
      "    (3): LadderEncoder(\n",
      "      (linear): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (batchnorm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (mu): Linear(in_features=64, out_features=8, bias=True)\n",
      "      (var): Linear(in_features=64, out_features=8, bias=True)\n",
      "    )\n",
      "    (4): LadderEncoder(\n",
      "      (linear): Linear(in_features=64, out_features=32, bias=True)\n",
      "      (batchnorm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (mu): Linear(in_features=32, out_features=4, bias=True)\n",
      "      (var): Linear(in_features=32, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (decoder): ModuleList(\n",
      "    (0): LadderDecoder(\n",
      "      (linear): Linear(in_features=4, out_features=32, bias=True)\n",
      "      (batchnrom): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (mu): Linear(in_features=32, out_features=8, bias=True)\n",
      "      (var): Linear(in_features=32, out_features=8, bias=True)\n",
      "    )\n",
      "    (1): LadderDecoder(\n",
      "      (linear): Linear(in_features=8, out_features=64, bias=True)\n",
      "      (batchnrom): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (mu): Linear(in_features=64, out_features=16, bias=True)\n",
      "      (var): Linear(in_features=64, out_features=16, bias=True)\n",
      "    )\n",
      "    (2): LadderDecoder(\n",
      "      (linear): Linear(in_features=16, out_features=128, bias=True)\n",
      "      (batchnrom): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (mu): Linear(in_features=128, out_features=32, bias=True)\n",
      "      (var): Linear(in_features=128, out_features=32, bias=True)\n",
      "    )\n",
      "    (3): LadderDecoder(\n",
      "      (linear): Linear(in_features=32, out_features=256, bias=True)\n",
      "      (batchnrom): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (mu): Linear(in_features=256, out_features=64, bias=True)\n",
      "      (var): Linear(in_features=256, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (recon): FinalLadderDecoder(\n",
      "    (linear): Linear(in_features=64, out_features=512, bias=True)\n",
      "    (recon): Linear(in_features=512, out_features=784, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# specify inputs for model\n",
    "input_dim = 784\n",
    "hidden_dims = [512, 256, 128, 64, 32]\n",
    "latent_dims = [64, 32, 16, 8, 4]\n",
    "\n",
    "num_epochs = 200\n",
    "lr = 1e-3\n",
    "\n",
    "model_lvae = LadderVAE(input_dim, hidden_dims, latent_dims).to(device)\n",
    "print(\"Number of model parameters: \", count_parameters(model_lvae))\n",
    "print(model_lvae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model parameters:  4870913\n"
     ]
    }
   ],
   "source": [
    "n_layers = 8\n",
    "hidden_dim = 256\n",
    "hidden_dims = [hidden_dim for _ in range(n_layers)]\n",
    "\n",
    "num_epochs = 200\n",
    "lr = 5e-5\n",
    "\n",
    "model_diff = DiffusionNet(hidden_dims=hidden_dims).to(device)\n",
    "print(\"Number of model parameters: \", count_parameters(model_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_diff.load_state_dict(torch.load('./trained_models/diffusion_model', map_location=device))\n",
    "model_lvae.load_state_dict(torch.load('./trained_models/LadderVAE', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './data'\n",
    "if not os.path.exists(root):\n",
    "    os.mkdir(root)\n",
    "\n",
    "if not os.path.exists('results'):\n",
    "    os.mkdir('results')\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if device.type == \"cuda:0\" else {}\n",
    "trainset = datasets.MNIST(root='./data', train=True,\n",
    "                          download=True, transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size,\n",
    "                          shuffle=True, **kwargs)\n",
    "\n",
    "testset = datasets.MNIST(root='./data', train=False,\n",
    "                          download=True, transform=transforms.ToTensor())\n",
    "test_loader = DataLoader(testset, batch_size=batch_size,\n",
    "                         shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model_lvae.eval()\n",
    "model_diff.eval()\n",
    "\n",
    "lst = []\n",
    "for batch_idx, (x, _) in enumerate(train_loader):\n",
    "    lst.append(x)\n",
    "    break\n",
    "\n",
    "\n",
    "idx = 30\n",
    "img = lst[0][idx].view(28, 28)\n",
    "\n",
    "model_lvae_img, _ = model_lvae(lst[0][idx].view(-1, 784).to(device))\n",
    "# model_diff_img, _, _ = model_diff(lst[0][idx].to(device))\n",
    "\n",
    "\n",
    "lst = []\n",
    "lst.append(img)\n",
    "for t in range(model_diff.T):\n",
    "    ts = torch.randint(low=t, high=t+1, size=(img.shape[0], )).to(device)\n",
    "    temp = model_diff.add_noise(lst[t].to(device), ts)\n",
    "    temp = model_diff.zero_one(temp)\n",
    "    lst.append(temp)\n",
    "\n",
    "model_diff.sample(1, img=lst[-1])\n",
    "\n",
    "\n",
    "# imm = img.detach().cpu().numpy()\n",
    "# imm2 = model_lvae_img.view(28, 28).detach().cpu().numpy()\n",
    "# imm3 = model_diff_img.view(28, 28).detach().cpu().numpy()\n",
    "\n",
    "# print(ssim(imm, imm2, data_range=imm.max() - imm.min()))\n",
    "# print(ssim(imm, imm3, data_range=imm.max() - imm.min()))\n",
    "\n",
    "# f, axarr = plt.subplots(1,3)\n",
    "# axarr[0].imshow(img.detach().cpu().numpy(), cmap='gray')\n",
    "# axarr[0].set_title('Ground-truth image')\n",
    "# axarr[1].imshow(model_lvae_img.view(28, 28).detach().cpu().numpy(), cmap='gray')\n",
    "# axarr[1].set_title('Bernoulli VAE Decoded Image')\n",
    "# axarr[2].imshow(model_diff_img.view(28, 28).detach().cpu().numpy(), cmap='gray')\n",
    "# axarr[2].set_title('Continuous Bernoulli VAE Decoded Image')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
